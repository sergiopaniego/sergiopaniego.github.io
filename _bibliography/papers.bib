@article{Fernndez2021RobustRT,
    title = {Robust Real-Time Traffic Surveillance with Deep Learning},
    author = {Jessica Fern{\'a}ndez and Jos{\'e} Mar{\'i}a Ca{\~n}as and Vanessa Fern{\'a}ndez and Sergio Paniego},
    journal = {Computational Intelligence and Neuroscience},
    year = {2021},
    volume = {2021},
    html = {https://www.hindawi.com/journals/cin/2021/4632353/},
    abstract = {Real-time vehicle monitoring in highways, roads, and streets may provide useful data both for infrastructure planning and for traffic management in general. Even though it is a classic research area in computer vision, advances in neural networks for object detection and classification, especially in the last years, made this area even more appealing due to the effectiveness of these methods. This study presents TrafficSensor, a system that employs deep learning techniques for automatic vehicle tracking and classification on highways using a calibrated and fixed camera. A new traffic image dataset was created to train the models, which includes real traffic images in poor lightning or weather conditions and low-resolution images. The proposed system consists mainly of two modules, first one responsible of vehicle detection and classification and a second one for vehicle tracking. For the first module, several neural models were tested and objectively compared, and finally, the YOLOv3 and YOLOv4-based network trained on the new traffic dataset were selected. The second module combines a simple spatial association algorithm with a more sophisticated KLT (Kanade–Lucas–Tomasi) tracker to follow the vehicles on the road. Several experiments have been conducted on challenging traffic videos in order to validate the system with real data. Experimental results show that the proposed system is able to successfully detect, track, and classify vehicles traveling on a highway on real time.},
    abbr={CIN},
    code = {https://github.com/JdeRobot/DetectionMetrics},
}

@misc{https://doi.org/10.48550/arxiv.2205.12124,
    doi = {10.48550/ARXIV.2205.12124},
    url = {https://arxiv.org/abs/2205.12124},
    arxiv = {2205.12124},
    author = {Blanco, Sergio Paniego and Mahna, Sakshay and Mishra, Utkarsh A. and Canas, JoseMaria},
    keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Memory based neural networks for end-to-end autonomous driving},
    publisher = {arXiv},
    year = {2022},
    copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
    abstract = {Recent works in end-to-end control for autonomous driving have investigated the use of vision-based exteroceptive perception. Inspired by such results, we propose a new end-to-end memory-based neural architecture for robot steering and throttle control. We describe and compare this architecture with previous approaches using fundamental error metrics (MAE, MSE) and several external metrics based on their performance on simulated test circuits. The presented work demonstrates the advantages of using internal memory for better generalization capabilities of the model and allowing it to drive in a broader amount of circuits/situations. We analyze the algorithm in a wide range of environments and conclude that the proposed pipeline is robust to varying camera configurations. All the present work, including datasets, network models architectures, weights, simulator, and comparison software, is open source and easy to replicate and extend.},
    abbr = {Arxiv},
    code = {https://github.com/JdeRobot/DeepLearningStudio},
    image={/assets/img/pub_img/transformer_transform.png},
}

@Article{s22124575,
    author = {Paniego, Sergio and Sharma, Vinay and Cañas, José María},
    title = {Open Source Assessment of Deep Learning Visual Object Detection},
    journal = {Sensors},
    volume = {22},
    year = {2022},
    number = {12},
    article-number = {4575},
    url = {https://www.mdpi.com/1424-8220/22/12/4575},
    PubMedID = {35746357},
    ISSN = {1424-8220},
    abstract = {This paper introduces Detection Metrics, an open-source scientific software for the assessment of deep learning neural network models for visual object detection. This software provides objective performance metrics such as mean average precision and mean inference time. The most relevant international object detection datasets are supported along with the most widely used deep learning frameworks. Different network models, even those built from different frameworks, can be fairly compared in this way. This is very useful when developing deep learning applications or research. A set of tools is provided to manage and work with different datasets and models, including visualization and conversion into several common formats. Detection Metrics may also be used in automatic batch processing for large experimental tests, saving researchers time, and new domain-specific datasets can be easily created from videos or webcams. It is open-source, can be audited, extended, and adapted to particular requirements. It has been experimentally validated. The performance of the most relevant state-of-the-art neural models for object detection has been experimentally compared. In addition, it has been used in several research projects, guiding in selecting the most suitable network model architectures and training procedures. The performance of the different models and training alternatives can be easily measured, even on large datasets.},
    doi = {10.3390/s22124575},
    html = {https://www.mdpi.com/1424-8220/22/12/4575},
    abbr = {Sensors},
    code = {https://github.com/JdeRobot/DetectionMetrics},
    image={/assets/img/pub_img/transformer_transform.png},
}
